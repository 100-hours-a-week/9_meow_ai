#!/usr/bin/env python3
"""
vLLM ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
í¬ìŠ¤íŠ¸ ë¬¸ì¥ ìƒì„±ì„ ìœ„í•œ ê°„ì†Œí™”ëœ vLLM ì„œë²„ ì‹¤í–‰
"""

import sys
import os
import argparse
from pathlib import Path
from huggingface_hub import snapshot_download
import logging
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ai_server.vLLM import VLLMLauncher, update_vllm_config


def download_huggingface_model(model_name: str, local_dir: str) -> str:
    """í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ"""
    try:
        logger.info(f"ğŸ“¥ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_name}")
        local_path = snapshot_download(
            repo_id=model_name,
            local_dir=local_dir,
            local_dir_use_symlinks=False,
            resume_download=True
        )
        logger.info(f"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
        return local_path
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def setup_lora_models(base_model_name: str, lora_adapter_name: str, models_dir: str) -> tuple[str, str]:
    """LoRA ëª¨ë¸ ì„¤ì • - ë² ì´ìŠ¤ ëª¨ë¸ê³¼ ì–´ëŒ‘í„° ë‹¤ìš´ë¡œë“œ"""
    models_path = Path(models_dir)
    models_path.mkdir(parents=True, exist_ok=True)
    
    # ë² ì´ìŠ¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    base_model_local = models_path / "base_model" 
    if not base_model_local.exists():
        logger.info(f"ğŸ”½ ë² ì´ìŠ¤ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ: {base_model_name}")
        base_model_path = download_huggingface_model(base_model_name, str(base_model_local))
    else:
        logger.info(f"ğŸ“ ê¸°ì¡´ ë² ì´ìŠ¤ ëª¨ë¸ ì‚¬ìš©: {base_model_local}")
        base_model_path = str(base_model_local)
    
    # ë² ì´ìŠ¤ ëª¨ë¸ ê²€ì¦
    if not validate_model_files(base_model_path, "base"):
        raise RuntimeError(f"ë² ì´ìŠ¤ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {base_model_path}")
    
    # LoRA ì–´ëŒ‘í„° ë‹¤ìš´ë¡œë“œ  
    lora_adapter_local = models_path / "lora_adapter"
    if not lora_adapter_local.exists():
        logger.info(f"ğŸ”½ LoRA ì–´ëŒ‘í„° ë‹¤ìš´ë¡œë“œ: {lora_adapter_name}")
        lora_adapter_path = download_huggingface_model(lora_adapter_name, str(lora_adapter_local))
    else:
        logger.info(f"ğŸ“ ê¸°ì¡´ LoRA ì–´ëŒ‘í„° ì‚¬ìš©: {lora_adapter_local}")
        lora_adapter_path = str(lora_adapter_local)
    
    # LoRA ì–´ëŒ‘í„° ê²€ì¦
    if not validate_model_files(lora_adapter_path, "lora"):
        raise RuntimeError(f"LoRA ì–´ëŒ‘í„° ê²€ì¦ ì‹¤íŒ¨: {lora_adapter_path}")
    
    return base_model_path, lora_adapter_path


def main():
    parser = argparse.ArgumentParser(description="í¬ìŠ¤íŠ¸ ìƒì„±ìš© vLLM ì„œë²„ ì‹œì‘")
    
    # ê¸°ë³¸ ëª¨ë¸ ì„¤ì • (í¬ìŠ¤íŠ¸ ìƒì„± ìµœì í™”)
    parser.add_argument("--base-model-name", 
                       default="naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B",
                       help="í—ˆê¹…í˜ì´ìŠ¤ ë² ì´ìŠ¤ ëª¨ë¸ ì´ë¦„")
    parser.add_argument("--lora-adapter-name", 
                       default="haebo/Meow-HyperCLOVAX-1.5B_LoRA_fp16_0527",
                       help="í—ˆê¹…í˜ì´ìŠ¤ LoRA ì–´ëŒ‘í„° ì´ë¦„")
    parser.add_argument("--models-dir", 
                       default="./models",
                       help="ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬")
    
    # ì„œë²„ ì„¤ì • (í¬ìŠ¤íŠ¸ ìƒì„±ì— í•„ìš”í•œ ìµœì†Œ ì˜µì…˜ë§Œ)
    parser.add_argument("--port", type=int, default=8001, help="ì„œë²„ í¬íŠ¸")
    parser.add_argument("--host", default="0.0.0.0", help="ì„œë²„ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--gpu-memory-utilization", type=float, default=0.8,
                       help="GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ")
    
    args = parser.parse_args()
    
    try:
        # LoRA ëª¨ë“œë¡œ í¬ìŠ¤íŠ¸ ìƒì„± ì„œë²„ ì‹œì‘
        logger.info("ğŸš€ í¬ìŠ¤íŠ¸ ìƒì„±ìš© LoRA ëª¨ë¸ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        base_model_path, lora_adapter_path = setup_lora_models(
            args.base_model_name,
            args.lora_adapter_name, 
            args.models_dir
        )
        
        # í¬ìŠ¤íŠ¸ ìƒì„± ìµœì í™” ì„¤ì •
        update_vllm_config(
            enable_lora=True,
            base_model_path=base_model_path,
            lora_modules=[f"lora={lora_adapter_path}"],
            model_path=base_model_path,
            port=args.port,
            host=args.host,
            gpu_memory_utilization=args.gpu_memory_utilization,
        )
        
        print("=" * 80)
        print("ğŸ¯ í¬ìŠ¤íŠ¸ ìƒì„±ìš© vLLM ì„œë²„ ì‹œì‘ ì¤‘...")
        print(f"ğŸ“¦ ë² ì´ìŠ¤ ëª¨ë¸: {args.base_model_name}")
        print(f"ğŸ”§ LoRA ì–´ëŒ‘í„°: {args.lora_adapter_name}")
        print(f"ğŸŒ ì„œë²„: {args.host}:{args.port}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {args.gpu_memory_utilization * 100:.1f}%")
        print("=" * 80)
        
        # vLLM ì„œë²„ ì‹œì‘
        launcher = VLLMLauncher()
        
        success = launcher.start_server()
        if success:
            print("âœ… í¬ìŠ¤íŠ¸ ìƒì„±ìš© vLLM ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print(f"ğŸ”— API ì—”ë“œí¬ì¸íŠ¸: http://{args.host}:{args.port}")
            print(f"ğŸ”— OpenAI í˜¸í™˜ API: http://{args.host}:{args.port}/v1")
            print("â¹ï¸  ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
            
            # ì„œë²„ ì‹¤í–‰ ìœ ì§€
            try:
                import signal
                
                def signal_handler(signum, frame):
                    print("\nğŸ›‘ ì„œë²„ ì¤‘ì§€ ì‹ í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤...")
                    launcher.stop_server()
                    sys.exit(0)
                
                signal.signal(signal.SIGINT, signal_handler)
                signal.signal(signal.SIGTERM, signal_handler)
                
                while True:
                    time.sleep(1)
                    
            except KeyboardInterrupt:
                print("\nâ¹ï¸  ì„œë²„ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤...")
                launcher.stop_server()
        else:
            print("âŒ vLLM ì„œë²„ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 