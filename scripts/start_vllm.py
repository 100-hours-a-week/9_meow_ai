#!/usr/bin/env python3
"""
vLLM ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
HyperCLOVAX-1.5B_LoRA_fp16 ëª¨ë¸ì„ ìœ„í•œ vLLM ì„œë²„ ì‹¤í–‰
"""

import sys
import os
import argparse
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from ai_server.vllm_server.vllm_launcher import VLLMLauncher
from ai_server.vllm_server.vllm_config import update_vllm_config


def main():
    parser = argparse.ArgumentParser(description="vLLM ì„œë²„ ì‹œì‘")
    parser.add_argument("--model-path", 
                       default="./models/haebo/Meow-HyperCLOVAX-1.5B_LoRA_fp16_0527",
                       help="LoRA ì–´ëŒ‘í„° ê²½ë¡œ")
    parser.add_argument("--base-model", 
                       default=None,
                       help="ë² ì´ìŠ¤ ëª¨ë¸ ê²½ë¡œ (LoRA ì‚¬ìš©ì‹œ í•„ìˆ˜)")
    parser.add_argument("--enable-lora", action="store_true",
                       help="LoRA ëª¨ë“œ í™œì„±í™”")
    parser.add_argument("--port", type=int, default=8001, help="ì„œë²„ í¬íŠ¸")
    parser.add_argument("--host", default="0.0.0.0", help="ì„œë²„ í˜¸ìŠ¤íŠ¸")
    parser.add_argument("--gpu-memory-utilization", type=float, default=0.8,
                       help="GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (0.0-1.0)")
    parser.add_argument("--max-model-len", type=int, default=4096,
                       help="ìµœëŒ€ ëª¨ë¸ ê¸¸ì´")
    parser.add_argument("--tensor-parallel-size", type=int, default=1,
                       help="í…ì„œ ë³‘ë ¬ ì²˜ë¦¬ í¬ê¸°")
    
    args = parser.parse_args()
    
    # LoRA ì„¤ì • ì²˜ë¦¬
    if args.enable_lora:
        if not args.base_model:
            print("âŒ LoRA ëª¨ë“œì—ì„œëŠ” --base-modelì´ í•„ìˆ˜ì…ë‹ˆë‹¤.")
            sys.exit(1)
        
        # LoRA ì„¤ì • ì—…ë°ì´íŠ¸
        update_vllm_config(
            enable_lora=True,
            base_model_path=args.base_model,
            lora_modules=[f"lora={args.model_path}"],
            model_path=args.model_path,  # LoRA ì–´ëŒ‘í„° ê²½ë¡œ
            port=args.port,
            host=args.host,
            gpu_memory_utilization=args.gpu_memory_utilization,
            max_model_len=args.max_model_len,
            tensor_parallel_size=args.tensor_parallel_size
        )
        
        print("=" * 60)
        print("vLLM ì„œë²„ ì‹œì‘ ì¤‘... (LoRA ëª¨ë“œ)")
        print(f"ë² ì´ìŠ¤ ëª¨ë¸: {args.base_model}")
        print(f"LoRA ì–´ëŒ‘í„°: {args.model_path}")
        print(f"ì„œë²„: {args.host}:{args.port}")
        print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {args.gpu_memory_utilization * 100:.1f}%")
        print("=" * 60)
    else:
        # ì¼ë°˜ ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸
        update_vllm_config(
            enable_lora=False,
            model_path=args.model_path,
            port=args.port,
            host=args.host,
            gpu_memory_utilization=args.gpu_memory_utilization,
            max_model_len=args.max_model_len,
            tensor_parallel_size=args.tensor_parallel_size
        )
        
        print("=" * 60)
        print("vLLM ì„œë²„ ì‹œì‘ ì¤‘...")
        print(f"ëª¨ë¸: {args.model_path}")
        print(f"ì„œë²„: {args.host}:{args.port}")
        print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {args.gpu_memory_utilization * 100:.1f}%")
        print("=" * 60)
    
    # vLLM ì„œë²„ ì‹œì‘
    launcher = VLLMLauncher()
    
    try:
        success = launcher.start_server()
        if success:
            print("vLLM ì„œë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"API ì—”ë“œí¬ì¸íŠ¸: http://{args.host}:{args.port}")
            print(f"OpenAI í˜¸í™˜ API: http://{args.host}:{args.port}/v1")
            print("ì„œë²„ë¥¼ ì¤‘ì§€í•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
            
            # ì„œë²„ ì‹¤í–‰ ìœ ì§€
            try:
                import signal
                import time
                
                def signal_handler(signum, frame):
                    print("\nğŸ›‘ ì„œë²„ ì¤‘ì§€ ì‹ í˜¸ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤...")
                    launcher.stop_server()
                    sys.exit(0)
                
                signal.signal(signal.SIGINT, signal_handler)
                signal.signal(signal.SIGTERM, signal_handler)
                
                while True:
                    time.sleep(1)
                    
            except KeyboardInterrupt:
                print("\nì„œë²„ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤...")
                launcher.stop_server()
        else:
            print("vLLM ì„œë²„ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 